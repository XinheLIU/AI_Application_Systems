# Feedback Estimation Papers

## Overview

Feedback的概念-click, convert（点击，购买，交易，etc）
    - (user, content, ads) - 素材，场景，广告商等因素
    - 某一种类型的广告在哪个发布商能够带来更多的点击，从而能够有针对性地对于某个发布商进行投放
数据-在广告点击率预估的问题中，正例的数目常常是负例的百分之一或者千分之一。这样造成的就是非常“不均衡”的数据集。（也是ctr预估不断出论文的原因)
  - 第一，上下文的特性信息非常重要。这两个广告可能是类型不同，可能展示的地区不同，因此并不能完全直接来对这两个广告进行比较。
  - 第二，广告 2 在旧金山地区的展示次数还比较少，因此 0.03 这个预估值可能是非常不准确的，或者说至少是不稳定的，它的误差要大于第一个广告。
目标函数 - 比搜索和推荐复杂
  - 真实的系统中，我们需要在很多候选可能的广告中，选出最优的一个或者几个显示在页面上。从某种程度上来说，这更像是一个排序问题。
  - 同时，对于不少 DSP（需求侧平台）来说，广告排序的最终目的是进行“竞拍”（Auction）。因此，最后估算广告的点击率以后，还需要看广告的竞价，由此来对广告是否会赢得竞拍从而被显示在页面上进行一个更加全面的估计。
算法
  - 二分类分析- logistic regression
    - 普通的逻辑回归并不适应大规模的广告点击率预估。有两个原因，
      - 第一，数据量太大。传统的逻辑回归参数训练过程都依靠牛顿法（Newton’s Method）或者 L-BFGS 等算法。这些算法并不太容易在大规模数据上得以处理。
      - 第二，不太容易得到比较稀疏（Sparse）的答案（Solution）。
    - FTRL - follow the regularized leader 参数在每一个数据点更新
      - 第一部分是一个用过去所有的梯度值（Gradients）来重权（Re-Weight）所有的参数值；
        - 第二部分是当前最新的参数值尽可能不偏差之前所有的参数值；
        - 第三个部分则是希望当前的参数值能够有稀疏的解（通过 L1 来直接约束）
  - Calibration
      - 文章也提出了需要对模型的最后预测进行调优（Calibration），使得模型的输出可以和历史的真实点击率分布相近。这一点对于利用点击率来进行计费显得尤为重要，因为有可能因为系统性的偏差，预测的数值整体高出或者整体低于历史观测值，从而对广告主过多计费或者过少计费。
  - tree models/GBDT
    - 点击率预估模型分为两个层次。也就是说，从最初的模型特性输入，需要经过两个不同的模型才对点击率做出最终的预测。这个两层架构对后来的很多点击率预估模型有巨大的影响。
      - 连续数值的特性已经被转换成了离散的数值。然后，这些离散的数值经过了一个 GBDT 树来进行特性转换
        - 第一，GBDT 可以对特性进行非线性组合。也就是说，GBDT 的输出一定是之前特性的非线性的转换，这是由树模型原本的性质所带来的，这个性质对于线性模型来说会有巨大的优势。
        - 第二，经过 GBDT 转换之后，树模型其实选择出了对目标有用的特性，因此这里还起到一个“特性筛选”（Feature Selection）的作用。也就是说，经过 GBDT 的模型，最后剩下的特性肯定是要远小于最初的输入特性的，毕竟有作用的特性是少数的
  - 深度模型
模型评估
- 比较通行的评测不均衡数据分类问题的指标是“曲线下面积”，或者简称为 AUC，这个评测办法可以算是一种替代方法。简单来说，AUC 就是看我们是不是能够把正例给排序到负例上面。也就是说，如果每一个正例和负例都有一个预测数值，那么我们按照这个数值排序，去数每一个正例下面有多少负例，然后对所有正例所对应的数取平均。AUC 的数值高，则代表我们可以把绝大多数正例排序到负例前面。
- AUC 的一个最大问题就是它并不在乎所有实例的绝对预测数值，而只在乎它们的相对位置。这在广告系统中可以说是一个非常大的缺陷。我们之前也提过，有很多广告系统组件依赖于对于广告点击率的精确预估，比如收费系统，流量预测等。因此，仅有一个相对位置的正确是不够的。 

## Classic Feedback Prediction Models

###  “Ad Click Prediction: a View from the Trenches“（2003） - Google

  - KDD 2013 年的工业论文组，在短短几年时间里就获得了近 200 次的文章引用数，不少公司争相研究其中的内容，希望能够复制类似的算法和技术。
    - 布兰登（H. Brendan McMahan）优化算法研究专家
    - 作者斯卡利（D. Sculley）从塔夫茨大学（Tufts University）博士毕业之后，一直在 Google 的匹兹堡分部工作，并着手研究大规模机器学习系统，其中重要的代表性研究成果是如何把回归问题和排序问题结合起来（发表于 KDD 2010 年）
      - 大规模版本的Rank SVm
  - 这篇文章提出了用一种叫 FTRL（Follow The Regularized Leader）的在线逻辑回归算法来解决上述问题。FTRL 是一种在线算法，因此算法的核心就是模型的参数会在每一个数据点进行更新。FTRL 把传统的逻辑回归的目标函数进行了改写。

### Practical Lessons from Predicting Clicks on Ads at Facebook(2014)

在这篇论文中，Facebook 团队提到了一个概念叫“归一化的交叉熵”，简称 NE，用于衡量广告系统的好坏。NE 实际上是一个比值，比值的分母是数据中观测到的实际的点击率的数值，也可以叫作数据的“背景估计”（Background Estimation）；而分子是某一个模型对点击率的估计。这样做的归一化，目的就是来看，在去除了背景估计的情况下，对点击率的估计是否依然好或者坏。
Facebook 的研究人员在这篇论文中提出的点击率预估模型分为两个层次。也就是说，从最初的模型特性输入，需要经过两个不同的模型才对点击率做出最终的预测。
第一，Facebook 的广告是社交广告，有其自身的特点和难点；第二，Facebook 对广告进行评测的指标主要有 AUC 和 NE；第三，Facebook 提出了两层模型的架构，其主要思想是先经过 GBDT 来进行特性转化，再经过一个线性分类器进行最后的预测。
经过了 GBDT 之后，Facebook 的研究者用树模型最后的叶节点当做新的特性，然后再学习了一个线性的分类模型。这里的思想其实和后来流行的深度学习的想法很类似，也就是先对输入特性进行非线性转换，然后再经过一个线性分类器来进行最后的预测。这个第二层的线性分类器可以用类似 SGD 的方法进行“在线学习”（Online Learning）。因此，学习到这样一个模型就相对比较容易。
  - Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf Herbrich, Stuart Bowers, and Joaquin Quiñonero Candela. Practical Lessons from Predicting Clicks on Ads at Facebook. Proceedings of the Eighth International Workshop on Data Mining for Online Advertising (ADKDD’14). ACM, New York, NY, USA, , Article 5 , 9 pages, 2014.

### 雅虎
Deepak Agarwal, Andrei Zary Broder, Deepayan Chakrabarti, Dejan Diklic, Vanja Josifovski, and Mayssam Sayyadian. Estimating rates of rare events at multiple resolutions. Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '07). ACM, New York, NY, USA, 16-25, 2007.2. 
Deepak Agarwal, Rahul Agrawal, Rajiv Khanna, and Nagaraj Kota. Estimating rates of rare events with multiple hierarchies through scalable log-linear models. Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '10). ACM, New York, NY, USA, 213-222, 2010.3. 
Nagaraj Kota and Deepak Agarwal.Temporal multi-hierarchy smoothing for estimating rates of rare events. Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD '11). ACM, New York, NY, USA, 1361-1369, 2011.4. Olivier Chapelle, Eren Manavoglu, and Romer Rosales. Simple and Scalable Response Prediction for Display Advertis
    - 列工作虽然在概念上有很高的学术和实践价值，特别是如何利用层次性信息来对预测进行平滑这个方面，但是从整体来说，预估方案变得非常复杂而且环节太多。
  - 雅虎后期的广告预估模型又从比较复杂的两层模式转换为了一层模式。这个转换主要是考虑到了整个流水线（Pipeline）的复杂度以及需要处理的数据规模逐渐变大，那么利用更加稳定和简单的方法就势在必行了。对于雅虎后期的广告预估模型，我参考论文《简单和可扩展的展示广告响应预测》（Simple and Scalable Response Prediction for Display Advertising）[4]，在这里为你简单做一个总结。
  - 总体来说，整个模型回到了相对简单的“对数几率回归”（Logistic Regression），并且直接对所有的特性（Feature）进行建模。这里面唯一可能和之前的很多工作不太一样的地方，是大量使用了“特性哈希”（Feature Hashing）的方法。简单来说，特性哈希就是把原来大规模的有可能是极其稀疏的特性给压缩到了一个固定维度的特性空间里。当然，这肯定会对精度等性能有一定影响，因此这是一个需要有一定取舍的决策。
    - 篇论文中，作者们还介绍了如何对大量的数据进行采样，以及如何利用配对的特性（也就是把两种不同的特性，比如广告商和地理位置进行配对）来自动产生更多的非线性因素的方法。那么这个一层模式的方法所达到的效果怎样呢？论文中论述，相比于之前的两层结构，这个方法所达到的效果有很大程度的提升。
    - yahoo研发人员提出了一个点击率估计方法，其实也是一种两层模型。第一层模型就是最原始的对点击率的估计，也就是类似我们上面所说的直接按照数据进行估计。当然，这里的问题我们刚才也已经提到了，就是估计的不稳定性。第二层模型是对第一层模型的修正。所谓修正，就是利用层次化信息来对原始的估计值进行“平滑”（Smoothing）。
    - 两个广告来自于同一个广告商，因此它们应该有一定的类似的点击率；两个广告被展示到同一个地区，它们也应该有一定的类似的点击率。这些层次信息给了我们一些启示，来对原始估计值进行修正。当然，根据我们这两个例子你就可以看出，一个广告可以受到多个层次信息的影响，比如广告商的层次信息，地理位置的层次信息，以及类别的层次信息等。所以，要想设计一套完善的基于层次信息的平滑方案也并非易事。
    - 雅虎在这方面的工作都围绕着一个主题，那就是如何对平滑方案进行创新。一种方法是利用“产生式模型”（Generative Model）的概念，把层次信息的叶子节点的数据产生过程，定义为基于其父节点数据的一个概率分布产生过程，从而把整个平滑方案的问题转换成为了一个有向无环图上的每个节点的后验概率参数的估计问题（参考文献[1]和[2]）。
    - 另外一种方法则采取了一个不太一样的思路，那就是在做平滑的时候，在这种产生式建模之后，还追加了一个过程，利用树模型来对平滑的结果进行再次修正，使得最后的结果能够达到更高的精度（参考文献[3]）。
  - 另外一个比较新颖的地方，就是对每一个特征维度的学习速率都有一个动态的自动调整。传统的随机梯度下降（Stochastic Gradient Descent）算法或是简单的在线逻辑回归都没有这样的能力，造成了传统的算法需要花很长时间来手工调学习速率等参数
    - 而 FTRL 带来的则是对每一个维度特征的动态学习速率，一举解决了手动调整学习算法的学习速率问题。简单说来，学习速率就是根据每一个维度目前所有梯度的平方和的倒数进行调整，这个平方和越大，则学习速率越慢。
  - 调优
    - 文章介绍了利用布隆过滤器（Bloom Filter）的方法，来动态决定某一个特征是否需要加入到模型中。虽然这样的方法是概率性的，意思是说，某一个特征即便可能小于某一个值，也有可能被错误加入，但是发生这样事件的概率是比较小的。通过布隆过滤器调优之后，模型的 AUC 仅仅降低了 0.008%，但是内存的消耗却减少了 60% 之多，可见很多特征仅仅存在于少量的数据中。
    - 来减少内存的消耗。比如利用更加紧凑的存储格式，而不是简单的 32 位或者 64 位的浮点数存储。作者们利用了一种叫 q2.13 的格式，更加紧凑地存储节省了另外 75% 的内存空间。
    - 每一步 FTRL 更新的时候，原则上都需要存储过去所有的梯度信息以及梯度的平方和的信息。文章介绍了一种非常粗略的估计形式，使得这些信息可以不必完全存储，让内存的消耗进一步降低
  - 失败
      - hashing trick 特征哈希降低内存
      - dropout, normalization


### （LASER: a scalable response prediction platform for online advertising-LinkedIn

  - LinkedIn 的广告预估模型。这个模型的一大“卖点”就是直接充分考虑了“冷启动”和“热启动”两种模式。
  - 于“冷启动”，“热启动”指的是我们已经掌握了用户或者广告的一定信息，然后利用这些历史信息来对点击率进行预测。这么说来，我们一般需要有两套对策，一套针对“冷启动”，一套针对“热启动”。LinkedIn 的方法就是希望通过一个模型来同时解决这两个问题。
    - Deepak Agarwal, Bo Long, Jonathan Traupman, Doris Xin, and Liang Zhang. LASER: a scalable response prediction platform for online advertising. Proceedings of the 7th ACM international conference on Web search and data mining (WSDM '14). ACM, New York, NY, USA, 173-182, 2014.
    - 第一部分，是利用用户、广告和上下文所建立的全局性预测。什么意思呢？就是我们利用用户特性、广告特性以及上下文特性来对点击率进行预测。这部分的核心思路就是这些特性所对应的系数是全局性的。也就是说，对于不同的用户、不同的广告以及不同的上下文所对应的系数是相同的。因为是全局性的系数，因此这部分其实提供了一种“冷启动”的需求，也就是不管是任何新的用户或是广告，只要有一定的特性，我们总能通过这部分得到一种粗略的估计。
    - 第二部分，是利用第一部分的用户、广告和上下文信息组成交叉特性，从而学习这些特性之间的关系。如果说第一部分直接就是线性的预测，那么第二部分其实就是“交叉项”形成的非线性的部分。我们之前在讲推荐系统的时候提到过“分解机”（Factorization Machines）这个模型，讲到过这种“交叉项”所带来的非线性预测的好处。虽然这里和分解机的构成不完全一样，但是整体上表达了相似的意思。
    - 第三部分，是 LinkedIn 模型提出来的独特之处（和其他公司模型不太一样的地方）。那就是同样是利用用户、广告和上下文特性，但是 LinkedIn 所提模型的系数则是每个用户、广告和上下文都不同。作者们认为这可以实现“热启动”效果。也就是说，当某个用户、某个广告或者某个上下文已经有比较多的数据以后，就可以依靠这些用户、广告或者上下文自己的系数了，而不仅仅依靠第一部分的全局系数。这个第三部分只有当数据比较多的时候才能够起作用。
作者们认为，刚才模型中所说的三个部分所需要的模型更新频率是不一样的。
    - 比如第一部分和第二部分都可以认为是全局模型，也就是说系数是全局性的。因此这些模型的变化会比较慢，作者们建议一个星期对模型进行一次更新。
    - 而第三部分则是在已经积累了历史信息后慢慢呈现出的效果，因此对于数据会非常敏感，而且每个用户和每个广告都是不同的系数，因此需要在短时间内，比如半个小时甚至几分钟内，就重新训练模型，以达到个性化的目的。
    - 提出的模型和 EE（Exploit & Explore）策略结合了起来。我们在讲推荐系统时介绍过 EE 的思路，简单回顾一下 EE 的目的，主要就是探索那些并没有太多机会被展示的物品，在这里也就是广告。我们刚才说了，所有的系数都加上了先验概率，因此其实可以很容易结合数据计算后验概率分布。有了后验概率分布，作者们提出了以汤普森采样为主的 EE 模式。这也可以算是论文提出模型的一大亮点。
    - 大规模的数据上对模型进行训练，这篇文章采用了一种 ADMM 算法。在文章提出来的时候，作者们还是希望能够利用单个服务器对所有的模型参数进行训练。和其他的算法相比，一般认为 ADMM 这种算法的收敛速度更快，但是，利用这种算法的其他公司并不太多。
    - 
### 《Twitter 时间轴上的广告点击率预估》（Click-through Prediction for Advertising in Twitter Timeline）

    - 社交广告的特点是，需要根据用户的社交圈子以及这些社交圈所产生的内容，而动态产生广告的内容。广告
    - 抖音社交？
    - 排序学习
      - 首先，排序学习中最基本的就是“单点法”（Pointwise）排序学习。回顾一下，单点法其实就是把排序学习的任务转化为分类问题。其实典型的就是直接利用“支持向量机”（SVM）或者对数几率回归模型。
      - 第二种比较常用的排序学习的方法就是“配对法”（Pairwise）排序学习。通俗地讲，配对法排序学习的核心就是学习哪些广告需要排到哪些广告之前。这种二元关系是根据一组一组的配对来体现的。学习的算法，主要是看能否正确学习这些配对的关系，从而实现整个排序正确的目的。对于配对法排序，我们依然可以使用对数几率回归。
      - 只是这个时候，我们针对的正负示例变成了某个广告比某个广告排名靠前，或者靠后。值得一提的是，通过配对法学习排序学习，对于一般的搜索结果来说，得到最后的排序结果以后就可以了。而对于广告来说，我们还需要对点击率进行准确的预测。这个我们之前提到过。于是在这篇文章中专门提到了如何从配对结果到点击率的预测。
      - 配对法学习排序完成以后的广告之间顺序是绝对的，但是绝对的数值可能是不太精确的。这里进行校准的目的是根据配对法产生的预测值，再去尽可能准确地转换为实际的点击率的数值。一般来说，这里就可以再使用一次对数几率回归。也就是说，这个模型的唯一特性就是配对法产生的预测数值，然后模型的目的是去估计或者说是预测最后的实际数值。这种使用一个回归模型来进行校准的方法，也用在比如要将支持向量机的结果转换成概率结果这一应用上。
      - 原理上讲，先有一个配对模型进行排序，然后再有一个校准模型对模型的绝对估计值进行重新校正，这是很自然的。但是在实际的工业级应用中，这意味着需要训练两个模型，那无疑就变成了比较繁复的步骤。所以，在这篇文章里，作者们想到了一种结合的办法，那就是结合单点法和配对法。
        - 具体来说，就是直接把两者的目标函数串联在一起。这样做的好处是，可以直接用现在已经有的训练方法，而且同时解决了排序和更加准确预测点击率的问题。
        - 串联多个目标函数是经常使用的一种技术。其目的和作用也就和这个串联的想法一样，就是希望针对多个不同的目标进行优化。一般来说，这里面的核心是，多个串联的目标函数需要共享模型参数才能形成有关联的总的大的目标函数；如果没有共享参数，那就仅仅是一种形式上的串联。
    - 前分享的 Facebook 的解决方案，并没有真正考虑往信息流里插入广告的难点，也就是广告的排序，依然把广告的排序问题当做分类问题，也就是用对数几率回归（Logistic Regression）来解决。
      - 这篇文章里，作者们也是用了 Facebook 提出的“归一化的交叉熵”，简称 NE 的概念以及业界比较常用的 AUC 来针对模型进行线下评价。

### 阿里巴巴广告预估

我们之前介绍了多个公司关于点击率或者转化率预估的案例。从这些案例中，你可能已经发现有两个非常重要的特征需要机器学习模型来处理。
- 第一，就是数据中呈现的非线性化的关系。也就是说，我们的模型必须在某一个地方考虑到特性之间的非线性表征，以及对于目标标签的非线性关系。
- 第二，就是数据的不均衡以及数据的稀疏性。有很多广告商是新广告商，很多广告是新广告。在这样的情况下，我们就必须要处理“冷启动”和“热启动”这两种局面。
从广告点击率预估的大规模数据中学习多段线性模型》（Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction）[1]这篇文章中，作者们提出了一种多段线性模型来解决我们刚刚说的这两个问题，这个模型简称为 LS-PLM（ Large Scale Piecewise Linear Model ）。
- 第一，就是数据中呈现的非线性化的关系。也就是说，我们的模型必须在某一个地方考虑到特性之间的非线性表征，以及对于目标标签的非线性关系。
- 第二，就是数据的不均衡以及数据的稀疏性。有很多广告商是新广告商，很多广告是新广告。在这样的情况下，我们就必须要处理“冷启动”和“热启动”这两种局面。
既然数据在整个空间里可能呈现非线性的关系，那么我们是否能够把整个空间分割成较小的区域，使得每个区域内依然可以使用线性模型来逼近这个区域内的数据点呢？其实在统计学习中，这种模型常常被叫作“混合模型”。在很多机器学习教科书中都会讲授的一种混合模型是“高斯混合模型”（Gaussian Mixture Model）。
- LS-PLM 在这篇论文的实际应用中，基本上可以被理解成为一种混合线性模型。这个模型的一个子模型叫作“分割函数”，也就是模型需要学习每一个数据点到底是依赖于哪一个线性模型来进行预测的。当然，这个分割是一种概率的分割。实际上，每一个数据点都依赖所有的线性模型来进行预测，只不过对每个模型的依赖程度不一样。对于每一个不同的线性模型来说，最大的不同就是每一个模型有自己的系数。也就是说，之前只有一个全局模型并且只有一组系数，相比之下，这里有多组系数来决定模型的预测效果。
- 很明显，对于 LS-PLM 来说，每一个局部都是线性的，但是在整体上依然是一个非线性的模型。LS-PLM 还借助了两种正则化机制。一种叫作 L1 正则，这种正则化主要是希望模型保留尽可能少的特性，从而达到对于模型特性的选择。另外，模型还采用了一种 L2,1 正则的方法，这种方法的目的也是特性选择，但是希望能够把一组特性全部选择或者全部置零。
- 作者们尝试了不同数目的数据分割，从 2 个到 36 个不等。最终，他们发现当数据分割为 12 个的时候，模型的效果达到最优，而之后，模型效果并没有明显提升。最终推出模型的 AUC 比直接使用一个对数概率回归的全局模型，效果要好 1.4%。
Kun Gai, Xiaoqiang Zhu, Han Li, Kai Liu, Zhe Wang. Learning Piece-wise Linear Models from Large Scale Data for Ad Click Prediction. CoRR abs/1704.05194 , 2017.2. 
广告点击率预估和图像处理的结合
- Tiezheng Ge, Liqin Zhao, Guorui Zhou, Keyu Chen, Shuying Liu, Huiming Yi, Zelin Hu, Bochao Liu, Peng Sun, Haoyu Liu, Pengtao Yi, Sui Huang, Zhiqiang Zhang, Xiaoqiang Zhu, Yu Zhang, Kun Gai. Image Matters: Jointly Train Advertising CTR Model with Image Representation of Ad and User Behavior. CoRR abs/1711.06505 , 2017.3. 


    - 这篇文章结合了近期好几个利用深度学习来进行图像处理和广告点击率预估的工作。首先，就是所有的特性都利用一个“嵌入层”（Embedding Layer）把原始的特性转换成为数值特性。这种思路我们在之前介绍文本处理，特别是 Word2Vec 的时候曾经进行了详细的讲解。
    - 而在这里，不管是文本信息还是图像信息，都根据自己的特点转换成为了数值特性。这里我们要解决的一个核心问题，就是用户和广告之间的匹配问题，这篇论文的模型是这么处理的。首先，对所有广告的 ID 及其图像进行单独的嵌入。然后对用户过去的喜好，特别是对图像的喜好进行了另外的嵌入，然后这些嵌入向量形成用户的某种“画像”。
    - 用户的画像和广告信息的嵌入被直接串联起来，形成最终的特征向量。在此之上，利用一个多层的神经网络来学习最后的点击率的可能性。在深度学习建模中，这种把多种来源不同的信息通过简单的拼接，然后利用多层神经网络来进行学习的方法非常普遍和实用。在这篇论文的介绍中，除了在模型上对图像进行处理以外，还有一个创新，就是提出了一个叫“高级模型服务器”（Advanced Model Server），简称 AMS 的架构理念。
    - AMS 是针对深度学习模型的大计算量而专门打造的计算体系。总体来说，AMS 的目的是把深度学习模型中的很多基础步骤进行拆分，然后把这些步骤部署到不同的服务器上，从而能够把复杂的模型拆分成细小的可以互相交流的步骤。从最终的实验结果上来看，基于深度学习的模型要比对数几率回归的模型好 2~3%。
  - Guorui Zhou, Chengru Song, Xiaoqiang Zhu, Xiao Ma, Yanghui Yan, Xingya Dai, Han Zhu, Junqi Jin, Han Li, Kun Gai. Deep Interest Network for Click-Through Rate Prediction. CoRR abs/1706.06978 , 2017.
    - DIN 依靠一种基本的模型架构，那就是先把所有的特性变换成嵌入向量，然后针对不同的特性进行划组，一些特性得以直接进入下一轮，另一些特性经过类似图像中的池化（Pooling）操作抽取到更加高级的特性。之后，所有的特性都被简单串联起来，然后再经过多层的深度神经网络的操作。
    - DIN 在这个架构的基础上，提出了一种新的“激活函数”（Activation Function），叫 DICE，目的是可以在不同的用户数据中灵活选择究竟更依赖于哪一部分数据。可以说，在某种意义上，这个架构非常类似深度学习中比较火热的 Attention 架构，其目的也是要看究竟那部分数据对于最终的预测更有效果。
    - 从最后的实验中看，不管是在内部数据还是外部公开的例如 MovieLens 或者 Amazon 的数据上，基于 DIN 的模型都比线性模型和其他的深度学习模型有显著的提高。


## 深度学习

在排序方面，深度神经网络已经崭露头角，包括前面讲融合模型时，专门讲到的 Wide&Deep 模型，也是深度学习在排序方面的贡献。除此之外，深度学习更多发挥作用的地方是特征表达上，各种嵌入技术得以让物品、用户、关系等对象的特征化有更好的输出。
Model Evaluation - AUC
https://arxiv.org/abs/1909.03602
https://zhuanlan.zhihu.com/p/133140002
probit, logit, tobit model

https://paperswithcode.com/task/click-through-rate-prediction


## Reference

[值得反复阅读广告方向论文](https://zhuanlan.zhihu.com/p/82820539)
Newton's Method and L-BFGS method
  - 推导 论文
  - https://www.hankcs.com/ml/l-bfgs.html

